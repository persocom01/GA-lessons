{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Neural Networks with Keras\n",
    "\n",
    "_Authors: Justin Pounders (ATL) and Riley Dallas (ATX)_\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Describe the basic `keras` workflow.\n",
    "- Train regression and classification neural networks using `keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "---\n",
    "\n",
    "`make_regression` is an excellent library for generating a random regression problem. This helps us focus on the model without having to worry about the dataset. \n",
    "\n",
    "In the cell below, use `make_regression` to generate 10,000 samples using 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "---\n",
    "\n",
    "We always want to have a validation set to test our model. Use the `train_test_split` function to split our `X` and `y` variables into a training set and a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `StandardScaler`\n",
    "---\n",
    "\n",
    "You want to scale your data for *any* model that uses Gradient Descent, which includes Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first Neural Network!!\n",
    "---\n",
    "\n",
    "Next stop, [The Singularity](https://en.wikipedia.org/wiki/Technological_singularity)!\n",
    "\n",
    "Creating a model in `keras` entails a few steps:\n",
    "1. Create your network topology\n",
    "2. Compile your model\n",
    "3. Fit your model\n",
    "\n",
    "We'll cover each step in the cells below.\n",
    "\n",
    "### Create your network topology\n",
    "---\n",
    "\n",
    "We'll create a simple network with:\n",
    "- an input layer\n",
    "- one hidden layer. As a general rule, you should use `'relu'` as your activation function for all hidden layers.\n",
    "- an output layer. \n",
    "\n",
    "For *all* regression problems, your output layer will be 1 neuron with *no* activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile your model\n",
    "---\n",
    "\n",
    "Whenever you compile your model, you have to specify a few things: \n",
    "1. What [loss function](https://keras.io/losses/) to use (depends on if it's regression, classification, etc)\n",
    "2. What optimizer to use (Always use `'adam'`)\n",
    "3. Optional: What additional [metrics](https://keras.io/metrics/) you'd like to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fit your model\n",
    "---\n",
    "\n",
    "When fitting your model, you need to specify a few things:\n",
    "1. The number of epochs: start with 10. Always easy to add more\n",
    "2. Your batch size: pick a number that is a power of 2\n",
    "3. Your validation data, which in this case is our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model predictions\n",
    "---\n",
    "\n",
    "Your `keras` model has a `.fit()` method, similar to `sklearn`. The only difference is `keras` returns a 2D `numpy` matrix (`sklearn` returns a 1D `numpy` array).\n",
    "\n",
    "Try it out in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification\n",
    "---\n",
    "\n",
    "`make_classification` is similar to `make_regression`, except now we're predicting a class (0 or 1).\n",
    "\n",
    "In the cell below, use `make_classification` to generate 10,000 samples using 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "---\n",
    "\n",
    "We always want to have a validation set to test our model. Use the `train_test_split` function to split our `X` and `y` variables into a training set and a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `StandardScaler`\n",
    "---\n",
    "\n",
    "You want to scale your data for *any* model that uses Gradient Descent, which includes Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Topology for Binary Classification\n",
    "---\n",
    "\n",
    "We'll create a simple network with:\n",
    "- an input layer, \n",
    "- one hidden layer. As a general rule, you should use `'relu'` as your activation function for all hidden layers.\n",
    "- an output layer. \n",
    "\n",
    "For *all* binary classification problems, your output layer will be 1 neuron with `'sigmoid'` activation function. Sigmoid squashes the output of our neuron to a value between 0 and 1, which is great for predicting probabilities. We'll use the probability for our loss function in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile your model\n",
    "---\n",
    "\n",
    "Whenever you compile your model, you have to specify a few things: \n",
    "1. What loss function to use: For binary classification, use `binary_crossentropy`. ([Description](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy))\n",
    "2. What optimizer to use (Always use `'adam'`)\n",
    "3. Optional: What additional [metrics](https://keras.io/metrics/) you'd like to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit your model\n",
    "---\n",
    "\n",
    "When fitting your model, you need to specify a few things:\n",
    "1. The number of epochs: start with 10. Always easy to add more\n",
    "2. Your batch size: pick a number that is a power of 2\n",
    "3. Your validation data, which in this case is our test set.\n",
    "\n",
    "When you fit a model, `keras` returns a `History` object. We need that in the next step, but for now, just save it to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing model training\n",
    "---\n",
    "\n",
    "Whenever you fit your `keras` model, it returns a `History` object ([link](https://keras.io/visualization/#training-history-visualization)) that can be used for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "---\n",
    "\n",
    "Using the `history` object, plot the model's accuracy (for both train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification\n",
    "---\n",
    "\n",
    "The `make_classification` function allows for multi-class problems as well. Simply increase the `n_classes` and voila!\n",
    "\n",
    "**NOTE**: You'll need to increase `n_informative` as you increase `n_classes`.\n",
    "\n",
    "In the cell below, let's create a dataset with three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding Targets\n",
    "---\n",
    "\n",
    "In `keras`, you have to one-hot encode your `y` if it contains more than two classes. We'll use `keras`' built-in `to_categorical` function to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "---\n",
    "\n",
    "We always want to have a holdout set to test our model. Use the `train_test_split` function to split our `X` and `y` variables into a training set and a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `StandardScaler`\n",
    "---\n",
    "\n",
    "Use an instance of `StandardScaler` to scale your `X_train` and `X_test` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Topology for Multi-class Classification\n",
    "---\n",
    "\n",
    "We'll create a simple network with:\n",
    "- an input layer\n",
    "- one hidden layer. As a general rule, you should use `'relu'` as your activation function for all hidden layers.\n",
    "- an output layer\n",
    "\n",
    "For *all* multi-class classification problems, your output layer will be the same number of neurons as the number of classes in your problem. The activation function will be `softmax`, which will normalize the predictions into probabilities that sum up to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile your model\n",
    "---\n",
    "\n",
    "Whenever you compile your model, you have to specify a few things: \n",
    "1. What loss function to use: For multi-class classification, use `categorical_crossentropy`. ([Description](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy))\n",
    "2. What optimizer to use (Always use `'adam'`)\n",
    "3. Optional: What additional [metrics](https://keras.io/metrics/) you'd like to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit your model\n",
    "---\n",
    "\n",
    "When fitting your model, you need to specify a few things:\n",
    "1. The number of epochs: start with 10. Always easy to add more\n",
    "2. Your batch size: pick a number that is a power of 2\n",
    "3. Your validation data, which in this case is our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing model training\n",
    "---\n",
    "\n",
    "Whenever you fit your `keras` model, it returns a `History` object ([link](https://keras.io/visualization/#training-history-visualization)) that can be used for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "---\n",
    "\n",
    "Using the `history` object, plot the model's accuracy (for both train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
