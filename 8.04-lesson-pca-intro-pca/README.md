# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Principal Component Analysis

---

## Materials We Provide


| Topic | Description | Link |
| --- | --- | --- |
| Lesson | Principal Component Analysis Jupyter Notebook | [Link](./starter-code.ipynb)|

> **Dataset description:** [Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality)

---

## Learning Objectives

*After this lesson, students will be able to:*

1. Differentiate between feature elimination and feature extraction.
2. Describe the PCA algorithm.
3. Implement PCA in `scikit-learn`.
4. Calculate and interpret proportion of explained variance.
5. Identify use cases for PCA.

---

## Student Requirements

*Before this lesson(s), students should already be able to:*

1. Construct a multiple linear regression model.
2. Interpret variance.
3. Know what a covariance or correlation matrix is.

---

## Lesson Outline

> **Total Time: 100 minutes**

I. **PCA** (100 minutes)

---

## OPTIONAL: Resources for Practice and Learning

- [Setosa.io PCA Visualization](http://setosa.io/ev/principal-component-analysis/)
- [Medium Article: A One-Stop Shop for Principal Component Analysis](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c)
- [Exceptional StackOverflow Answer to Understanding PCA](http://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)
- [A Semi-Academic Walkthrough of PCA Building Blocks](http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf)
- [Eigenvalues and Eigenvectors Video](https://www.youtube.com/watch?v=PFDu9oVAE-g)
- [PCA Documentation in `sklearn`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)
- [PCA Explanation on AnalyticsVidhya, includes R and Python code](https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/)
- [An Introduction to Statistical Learning with Applications in R, PCA is in Sections 6.3, 6.7, 10.2](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf)
- [Notes on PCA from Penn State University's Applied Multivariate Statistical Analysis Course](https://onlinecourses.science.psu.edu/stat505/node/49)
- [Intuitive Description of Positive Definite Matrices](https://towardsdatascience.com/what-is-a-positive-definite-matrix-181e24085abd)
- [What are Eigenvaalues and Eigenvectors? A Medium post.](https://medium.com/fintechexplained/what-are-eigenvalues-and-eigenvectors-a-must-know-concept-for-machine-learning-80d0fd330e47)
- [StackExchange: What is the problem with p < n?](https://stats.stackexchange.com/questions/385711/what-is-the-problem-with-p-n)
---
